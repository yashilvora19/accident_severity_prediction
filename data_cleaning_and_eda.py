# -*- coding: utf-8 -*-
"""Data_Cleaning_and_EDA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gToO0pPIhtKjnyFanxqAR1pWLrQaOwNQ
"""

! git clone https://github.com/yashilvora19/CSE-151-EEG-Project.git

# import libraries, other imports are as we go through encoding
import pandas as pd
import numpy as np
import seaborn as sns

accident = pd.read_csv('/content/CSE-151-EEG-Project/accident_data.csv')
accident.head()

"""## Data Cleaning"""

accident.shape

# get all the datatypes
# date is a str
accident.dtypes

# number of unique values in each column
for col in accident.columns:
  print(f'{col}: {accident[col].nunique()}')

# make a copy of accident dataframe
accident_copy = accident.copy()

# get general idea of min max for the numerical columns (no anomalies)
accident_copy.describe()

"""Accident_Severity"""

# turning Severity into numbers
to_num = {'Serious': 1, 'Slight': 0 , 'Fatal': 2}
accident_copy['Accident_Severity'] = accident['Accident_Severity'].replace(to_num)

"""Accident Date"""

# turn dates column into three columns: day, month, year
accident_copy['Day'] = accident['Accident Date'].str.split('-').apply(lambda x: int(x[0]))
accident_copy['Month'] = accident['Accident Date'].str.split('-').apply(lambda x: int(x[1]))
accident_copy['Year'] = accident['Accident Date'].str.split('-').apply(lambda x: int(x[2]))

"""Light_Conditions"""

# assume NaN for 'Darkness - lighting unknown'
accident_copy['Light_Conditions'] = accident['Light_Conditions'].replace('Darkness - lighting unknown', np.NaN)

"""District Area"""

# rename District Area so it is consistent in column formatting
accident_copy = accident_copy.rename(columns={'District Area': 'District_Area'})

"""Weather_Conditions"""

# weather conditions seem to have combinations, so we could one hot encode it instead
# the categories include 'Fine', 'High Winds', 'Raining', 'Snowing', 'Fog or mist', 'Other'

# first split up the labels into lists
accident_copy['Weather_Conditions'] = accident['Weather_Conditions'].apply(
    lambda x: ['Fine'] if x == 'Fine no high winds'
    else ['Raining'] if x == 'Raining no high winds'
    else ['Fine', 'High winds'] if x == 'Fine + high winds'
    else ['Raining', 'High winds'] if x == 'Raining + high winds'
    else ['Snowing'] if x == 'Snowing no high winds'
    else ['Fog or mist'] if x == 'Fog or mist'
    else ['Snowing', 'High winds'] if x == 'Snowing + high winds'
    else ['Other'] if x == 'Other'
    else np.NaN
)

"""Vehicle_Type"""

# assume NaN for 'Data missing or out of range'
accident_copy['Vehicle_Type'] = accident['Vehicle_Type'].replace('Data missing or out of range', np.NaN)

# find out the current number of missing values in the dataset
accident_copy.isnull().sum()

# drop all NaN values
accident_copy = accident_copy.dropna()
# Also drop Accident Date column
accident_copy = accident_copy.drop(columns='Accident Date')
print(f'Before dropping missing values: {accident.shape[0]} rows')
print(f'After dropping missing values: {accident_copy.shape[0]} rows')

# cleaned, but before encoding
accident_copy.head()

"""## Exploring Data"""

sns.pairplot(accident_copy)

# plot a correlation heatmap to see the correlation between features
# seems like extremely low correlation between Accident Severity and all other columns
# highest is Number of Casualties, at 0.088
sns.heatmap(accident_copy.corr(), vmin=-1, vmax=1, center=0, annot=True, cmap= 'RdBu')

"""## Encoding"""

# Use One Hot Encoder on all categorical columns except Weather_Conditions
from sklearn.preprocessing import OneHotEncoder
# categorical columns include Light_Conditions, District_Area,
# Road_Surface_Conditions, Road_Type,	Urban_or_Rural_Area,
# Weather_Conditions, Vehicle_Type

categorical = ['Light_Conditions', 'Road_Surface_Conditions', 'Road_Type',	'Urban_or_Rural_Area', 'Vehicle_Type']

for col in categorical:
  ohe = OneHotEncoder()
  categorical_ohe = ohe.fit_transform(accident_copy[[col]]).toarray()
  df = pd.DataFrame(categorical_ohe, columns=list(ohe.categories_[0]))
  print(df)

# use MultiLabelBinarizer on Weather_Conditions??
from sklearn.preprocessing import MultiLabelBinarizer
mlb = MultiLabelBinarizer()
weather = mlb.fit_transform(accident_copy['Weather_Conditions'])
# one for everything that was in the weatehr condition that day
pd.DataFrame(weather, columns=mlb.classes_)

